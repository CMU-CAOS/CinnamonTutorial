{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cinnamon: A Framework For Scale Out Encrypted AI\n",
    "## Notebook 2: Encrypted AI\n",
    "\n",
    "In this tutorial, we will run an encrypted logistic regression inference.\n",
    "\n",
    "Logistic Regression Model Credits: [TenSEAL](https://github.com/OpenMined/TenSEAL/blob/main/tutorials/Tutorial%201%20-%20Training%20and%20Evaluation%20of%20Logistic%20Regression%20on%20Encrypted%20Data.ipynb)\n",
    "\n",
    "Author:\n",
    "- Siddharth Jayashankar (sidjay@cmu.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 \n",
    "In this exercise, we will write an encrypted logistic regression model in the Cinnamon DSL. The logistic regression model predicts the 10 year risk of a patient developing Coronary Heart Disease (CHD). The model we will use has been pre-trained on the [Framingham](https://www.kaggle.com/code/helddata/logistic-regression-by-framingham-heart-study?scriptVersionId=86142061) dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Logistic Regression Model\n",
    "The logistic regression model consists of a linear layer followed by a sigmoid function.\n",
    "\n",
    "The sigmoid function is a not expressible as a composition of multiplications, rotations and additions. Thus, we need to find a suitable polynomial approximation for it.\n",
    "\n",
    "We use the approximation `sigmoid_poly(x) = 0.5 + 0.197 * x - 0.004 * x**3` from https://eprint.iacr.org/2018/462.pdf to approximate the sigmoid function. This approximiation is good in the range [-5,5] and most of the values in the logistic regression inference lie in this range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, use_sigmoid_poly=True):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(in_features=8, out_features=1, bias=True)\n",
    "        self.use_sigmoid_poly=use_sigmoid_poly\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_poly(x):\n",
    "        # We use the polynomial approximation of degree 3\n",
    "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
    "        # from https://eprint.iacr.org/2018/462.pdf\n",
    "        # which fits the function pretty well in the range [-5,5]\n",
    "        return 0.5 + 0.197 * x - 0.004 * (x**3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        linear = self.lr(x)\n",
    "        if self.use_sigmoid_poly:\n",
    "            out = LR.sigmoid_poly(linear)\n",
    "        else:\n",
    "            out = torch.sigmoid(linear)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the test data for the model. This dataset contains health related data of several patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data.pth\"\n",
    "data = torch.load(file_path)\n",
    "x_test,y_test = data[\"x_test\"], data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's ensure that our polynomial approximation of sigmoid actually works. We can do this by comparing the inference accuracies we obtain using the original sigmoid function and our polynomial approximation of the sigmoid function. If the difference between the two is acceptable, we can be confident that our choice of polynomial approximation is a good one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y):\n",
    "    model = model.eval()\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "# Load the model\n",
    "model = LR(use_sigmoid_poly=False)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model_poly = LR(use_sigmoid_poly=True)\n",
    "model_poly.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "model_accuracy = accuracy(model, x_test, y_test)\n",
    "model_poly_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"Model(sigmoid)      accuracy on plain test_set: {model_accuracy}\")\n",
    "print(f\"Model(sigmoid poly) accuracy on plain test_set: {model_poly_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the difference in accuracies is negligible. This gives us confidence that our choice of approximation for the sigmoid function works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Coming up with a data layout\n",
    "FHE operations: addition and multiplication are pointwise operations on groups of `SLOTS` values. However, what our logistic regression implementation requires is a matrix vector product between the weights and the samples. Thus, we need a way to layout these matrices in the slots. This is also called packing values.\n",
    "\n",
    "Looking at the implementation of the linear layer, we observe that each prediction `Pred[i]` is computed as a dot product between the sample and the weight matrix and then a bias is added. Finally, the sigmoid of the value is computed. Thus,\n",
    "\n",
    "```\n",
    "Pred[i] = 0\n",
    "for j in range(8):\n",
    "    Pred[i] += Samples[i][j] * Weights[j] \n",
    "Pred[i] += Bias\n",
    "Pred[i] = sigmoid(Pred[i])\n",
    "\n",
    "```\n",
    "\n",
    "A simple way to layout this computation is by first laying the sample matrix in the row major order. This will occupy (n_samples x n_features) = (334 x 8) = 2672 slots. The remaining slots can be set to zero. To align the weight matrix with each slot, we pack the weight matrix in a row major order and repeat it for each of the samples.\n",
    "\n",
    "Thus, \\\n",
    "`samples_packed[8*i + j] = Samples[i][j]` \\\n",
    "`weights_packed[8*i + j] = Weights[j]`\n",
    "\n",
    "The multiplication operation between the samples and the weights can be implemented as a pointwise multiplication. i.e. \\\n",
    "`product[8*i + j] = samples_packed[8*i + j] * weights_packed[8*i + j] = Samples[i][j] * Weights[j]`\n",
    "\n",
    "However, we still have to work out the dot product. This is where we make use of rotations. The figure shows how roatation and summation can be used to compute the sum of values in a ciphertext. \n",
    "\n",
    "![image](images/RotateAndSum.jpg)\n",
    "\n",
    "In general, there can be several possible layouts for a program. The layout selected will influence the structure of the FHE program. Layouts can differ in several ways like the number of ciphertexts required and the number of operations needed to perform the compuatation. Exploring these tradeoffs and automatically finding an efficient layout is an exciting research direction.\n",
    "\n",
    "\n",
    "The sigmoid function is applied pointwise to the output of the linear layer so that doesn't require much consideration in terms of layout. However, implementing a polynomial in FHE can be quite tedious and time consuming. \n",
    "\n",
    "\n",
    "Now that we have the layout representation decided, let's write the program in the Cinnamon DSL. I have already provided an implementation of the sigmoid function as efficiently and correctly implementing a polynomial can be tedious and time consuming. Note that since Cinnamon is an embedded DSL, we can easily make use of python features like functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack x_test in row-major order\n",
    "SLOTS = 32*1024\n",
    "import numpy as np\n",
    "samples = x_test.numpy()\n",
    "weights = model.lr.weight.detach().numpy()[0]\n",
    "bias = model.lr.bias.detach().numpy()\n",
    "\n",
    "samples_packed = np.zeros(SLOTS, dtype=np.float32)\n",
    "weights_packed = np.zeros(SLOTS, dtype=np.float32)\n",
    "bias_packed = np.zeros(SLOTS, dtype=np.float32)\n",
    "\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    for j in range(8):\n",
    "        samples_packed[i * 8 + j] = samples[i,j]\n",
    "\n",
    "# Pack model weights in row-major order\n",
    "for i in range(x_test.shape[0]):\n",
    "    for j in range(8):\n",
    "        weights_packed[i * 8 + j] = weights[j]\n",
    "\n",
    "# Pack model biases in row-major order\n",
    "for i in range(x_test.shape[0]):\n",
    "    bias_packed[i * 8:(i + 1) * 8] = bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cinnamon.dsl import *\n",
    "from cinnamon.compiler import cinnamon_compile\n",
    "TOP_LEVEL = 51\n",
    "NUM_CHIPS=1\n",
    "RNS_BIT_SIZE =28\n",
    "\n",
    "\n",
    "\n",
    "lr_program = CinnamonProgram('LogisticRegression',RNS_BIT_SIZE,NUM_CHIPS)\n",
    "with lr_program:\n",
    "\n",
    "    SCALE = 56\n",
    "    def sigmoid(x):\n",
    "        # 0.5 + 0.197 * x - 0.004 * (x**3)\n",
    "        x2 = (x * x).relinearize().rescale().rescale()\n",
    "        xc3 = x * PlaintextInput(\"c3\",3*SCALE - x2.scale() -x.scale() ,x.level(),scalar=True)\n",
    "        x3 = x2 * xc3.rescale().rescale()\n",
    "        x3 = x3.relinearize()\n",
    "        x1 = x * PlaintextInput(\"c1\",2*SCALE - x.scale(),x.level(),scalar=True)\n",
    "        s = x3 + x1.modswitch().modswitch()\n",
    "        s = s.rescale().rescale()\n",
    "        c0 = PlaintextInput(\"c0\",s.scale(),s.level(),scalar=True)\n",
    "        s = s + c0\n",
    "        return s\n",
    "\n",
    "    def dot_product(A,B):\n",
    "        ## TODO: Implement Dot Product Using Rotate and Sum\n",
    "        return\n",
    "\n",
    "    level = TOP_LEVEL\n",
    "    ## TODO: Create Inputs for X and W\n",
    "    X = CiphertextInput('x')\n",
    "    w = PlaintextInput('w')\n",
    "    # Compute Dot Product\n",
    "    dp = dot_product(X,w)\n",
    "    dp = dp.rescale().rescale()\n",
    "    ## TODO: Create Input for Bias\n",
    "    b = PlaintextInput('b')\n",
    "    dp = dp + b\n",
    "    pred = sigmoid(dp)\n",
    "    Output('pred', pred)\n",
    "\n",
    "lr_program_dir = \"lr_program_outputs\"\n",
    "!mkdir -p \"{lr_program_dir}\"\n",
    "cinnamon_compile(lr_program,TOP_LEVEL,1,1024,f\"{lr_program_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNS_PRIMES = [204865537, 205651969, 206307329, 207880193, 209059841, 210370561, 211025921, 211812353, 214171649, 215482369, 215744513, 216137729, 216924161, 217317377, 218628097, 219676673, 220594177, 221249537, 222035969, 222167041, 222953473, 223215617, 224002049, 224133121, 225574913, 228065281, 228458497, 228720641, 230424577, 230686721, 230817793, 231473153, 232390657, 232652801, 234356737, 235798529, 236584961, 236716033, 239337473, 239861761, 240648193, 241827841, 244842497, 244973569, 245235713, 245760001, 246415361, 249561089, 253100033, 253493249, 254279681, 256376833, 256770049, 257949697, 258605057, 260571137, 260702209, 261488641, 261881857, 263323649, 263454721, 264634369, 265420801, 268042241]\n",
    "\n",
    "class ValueMeta:\n",
    "    def __init__(self, scale, level):\n",
    "        self.scale = scale\n",
    "        self.level = level\n",
    "        if self.level <= 0:\n",
    "            raise ValueError(\"Level must be positive\")\n",
    "        \n",
    "    def rescale(self):\n",
    "        return ValueMeta(self.scale/RNS_PRIMES[self.level -1],self.level-1)\n",
    "\n",
    "    def __mul__(self,other):\n",
    "        if not isinstance(other,ValueMeta):\n",
    "            raise ValueError(\"Must multiply by ValueMeta\")\n",
    "        if self.level != other.level:\n",
    "            raise ValueError(\"Levels must be the same for Multiplication\")\n",
    "        return ValueMeta(self.scale*other.scale,self.level)\n",
    "\n",
    "    def __add__(self,other):\n",
    "        if not isinstance(other,ValueMeta):\n",
    "            raise ValueError(\"Must multiply by ValueMeta\")\n",
    "        if self.level != other.level:\n",
    "            raise ValueError(\"Levels must be the same for Addition\")\n",
    "        return ValueMeta(self.scale,self.level)\n",
    "\n",
    "    def __lsfhift__(self,_):\n",
    "        return ValueMeta(self.scale,self.level)\n",
    "\n",
    "    def __rsfhift__(self,_):\n",
    "        return ValueMeta(self.scale,self.level)\n",
    "\n",
    "    def modswitch(self):\n",
    "        return ValueMeta(self.scale,self.level-1)\n",
    "\n",
    "def sigmoid_inputs(xM,sigmod_out_scale):\n",
    "    Inputs = {}\n",
    "    OutScale = {}\n",
    "    coeffs = [0.5,0.197,0,-0.004]\n",
    "    x2M = (xM * xM).rescale().rescale()\n",
    "    c3scale = sigmod_out_scale\n",
    "    for i in range(4):\n",
    "        c3scale *= RNS_PRIMES[xM.level-1-i]\n",
    "    c3scale = c3scale/(xM.scale*x2M.scale)\n",
    "    c3M = ValueMeta(c3scale,xM.level)\n",
    "    Inputs[\"c3\"] = (coeffs[3],c3M.scale)\n",
    "    c1scale = sigmod_out_scale\n",
    "    for i in range(2,4):\n",
    "        c1scale *= RNS_PRIMES[xM.level-1-i]\n",
    "    c1scale = c1scale/xM.scale\n",
    "    c1M = ValueMeta(c1scale,xM.level)\n",
    "    Inputs[\"c1\"] = (coeffs[1],c1M.scale)\n",
    "    x3M = xM * c3M\n",
    "    x3M = x3M.rescale().rescale() * x2M\n",
    "    x1M = xM * c1M\n",
    "    x1M = x1M.modswitch().modswitch()\n",
    "    sM = x3M + x1M  \n",
    "    sM = sM.rescale().rescale()\n",
    "    c0M = ValueMeta(sM.scale,sM.level)\n",
    "    Inputs[\"c0\"] = (coeffs[0],c0M.scale)\n",
    "    return (Inputs,OutScale,sM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_inputs = {}\n",
    "lr_output_scales = {}\n",
    "\n",
    "level = TOP_LEVEL\n",
    "scale = 1 << 56\n",
    "lr_inputs[\"x\"] = (samples_packed,scale)\n",
    "lr_inputs[\"w\"] = (weights_packed,scale)\n",
    "wM = ValueMeta(scale,level)\n",
    "yM = ValueMeta(scale,level)\n",
    "lM = (wM * yM).rescale().rescale()\n",
    "lr_inputs[\"b\"] = (bias_packed,lM.scale)\n",
    "lr_output_scales[\"l\"] = lM.scale\n",
    "(sigmoidInputs,sigmoidOutScale,sM) = sigmoid_inputs(lM,scale)\n",
    "lr_inputs.update(sigmoidInputs)\n",
    "lr_output_scales.update(sigmoidOutScale)\n",
    "lr_output_scales[\"pred\"] = sM.scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we see that our choice of polynomial approximation for the sigmoid function results in no drop in accuracy. This is great news for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cinnamon Compiler is a python embedded DSL. Let's import the Cinnamon modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a simple program to add two numbers. We first create a `CinnamonProgram` object. The first argument to the constructor is the name of the program. If you don't understand the other arguments, don't worry, these will be made clear later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to create two ciphertexts in the program and add them together. But before that, let's introduce two concepts of CKKS-FHE ciphertexts: scale and level.\n",
    "\n",
    "Cinnamon uses the information about the scale and levels provided here to type check the program. If you add values with incompatible scales and levels, the compiler will produce an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Emulating The Program\n",
    "Now, that we have compiled the program, we want to make sure that our program and the compiler output is actually what we want it to be. To test this, we use the Cinnamon emulator. The Cinnamon emulator reads in Cinnamon assembly and emulates the instructions on a CPU. But before, we do that, we need to actually assign values and scale information to our program inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the cinnamon emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cinnamon_emulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a secret key to encrypt and decrypt our values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "def generate_secret_key(Slots,HammingWeight=32):\n",
    "    secretKey = [0]*(2*Slots)\n",
    "    count = 0\n",
    "    while count < HammingWeight:\n",
    "        pos = random.randint(0,2*Slots-1)\n",
    "        if secretKey[pos] != 0:\n",
    "            continue\n",
    "        val = random.randint(0,1)\n",
    "        if val == 0:\n",
    "            secretKey[pos] = -1\n",
    "        elif val == 1:\n",
    "            secretKey[pos] = 1\n",
    "        else:\n",
    "            raise Exception(\"\")\n",
    "        count += 1\n",
    "    return secretKey\n",
    "\n",
    "secretKey = generate_secret_key(SLOTS,HammingWeight=SLOTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the ciphertexts and emulate the encrypted program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = cinnamon_emulator.Context(SLOTS,RNS_PRIMES)\n",
    "encryptor = cinnamon_emulator.CKKSEncryptor(context,secretKey)\n",
    "emulator = cinnamon_emulator.Emulator(context)\n",
    "\n",
    "base_dir = lr_program_dir\n",
    "emulator.generate_and_serialize_evalkeys(f\"{base_dir}/evalkeys\",f\"{base_dir}/program_inputs\",encryptor)\n",
    "emulator.generate_inputs(f\"{base_dir}/program_inputs\",f\"{base_dir}/evalkeys\",lr_inputs,encryptor)\n",
    "emulator.run_program(f\"{base_dir}/instructions\",NUM_CHIPS,1024)\n",
    "emulator_outputs = emulator.get_decrypted_outputs(encryptor,lr_output_scales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's collect the outputs of the encrypted program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_predictions = emulator_outputs[\"pred\"][0::8][:y_test.shape[0]]\n",
    "y_test_np = y_test.flatten().numpy()\n",
    "encrypted_accuracy = (np.abs(encrypted_predictions-y_test_np) < 0.5).mean()\n",
    "print(f\"Model(sigmoid)      accuracy on plain test_set:     {model_accuracy}\")\n",
    "print(f\"Model(sigmoid poly) accuracy on plain test_set:     {model_poly_accuracy}\")\n",
    "print(f\"Model(sigmoid poly) accuracy on encrypted test_set: {encrypted_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encrypted model inference provides the same accuracy as the plaintext model inference! And the server learnt nothing about the data of our patients. This example illustrates the power of encrytped AI: you can avail the services of an AI model without compromising your sensitive data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have just run your very first encrypted AI inference using Cinnamon. This marks the end of notebook 2. In [notebook3](../notebook3/notebook3.ipynb), we will see how the Cinnamon compiler can parallelize code and use the Cinnamon architectural simulator to see Cinnamon's scale out features in action."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
